


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.masked_multistream &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
  
  
  
    <link rel="canonical" href="https://pytorchvideo.org/docs/api/models/masked_multistream.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Overview" href="../../docs/data.html" />
    <link rel="prev" title="pytorchvideo.models.memory_bank" href="memory_bank.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../docs/models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Models API</a> &gt;</li>
        
      <li>pytorchvideo.models.masked_multistream</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/api/models/masked_multistream.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="pytorchvideo-models-masked-multistream">
<h1>pytorchvideo.models.masked_multistream<a class="headerlink" href="#pytorchvideo-models-masked-multistream" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-pytorchvideo.models.masked_multistream"></span><dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.MaskedTemporalPooling">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">MaskedTemporalPooling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedTemporalPooling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedTemporalPooling" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies temporal pooling operations on masked inputs. For each pooling operation
all masked values are ignored.</p>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.MaskedTemporalPooling.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedTemporalPooling.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedTemporalPooling.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>method (str): the method of pooling to use. Options:</dt><dd><p>‘max’: reduces temporal dimension to each valid max value.
‘avg’: averages valid values in the temporal dimension.
‘sum’: sums valid values in the temporal dimension.
Note if all batch row elements are invalid, the temporal dimension is
pooled to 0 values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.MaskedTemporalPooling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedTemporalPooling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedTemporalPooling.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – tensor with shape (batch_size, seq_len, feature_dim)</p></li>
<li><p><strong>mask</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – bool tensor with shape (batch_size, seq_len).
Sequence elements that are False are invalid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with shape (batch_size, feature_dim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.TransposeMultiheadAttention">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">TransposeMultiheadAttention</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">feature_dim</span></em>, <em class="sig-param"><span class="n">num_heads</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeMultiheadAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeMultiheadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for nn.MultiheadAttention which first transposes the input tensor
from (batch_size, seq_len, feature_dim) to (seq_length, batch_size, feature_dim),
then applies the attention and transposes the attention outputs back to the input
shape.</p>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">feature_dim</span></em>, <em class="sig-param"><span class="n">num_heads</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeMultiheadAttention.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_dim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – attention embedding dimension</p></li>
<li><p><strong>num_heads</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of attention heads</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.attention_weights">
<em class="property">property </em><code class="sig-name descname">attention_weights</code><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.attention_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Contains attention weights from last forward call.</p>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeMultiheadAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeMultiheadAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – tensor of shape (batch_size, seq_len, feature_dim)</p></li>
<li><p><strong>mask</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – bool tensor with shape (batch_size, seq_len).
Sequence elements that are False are invalid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with shape (batch_size, seq_len, feature_dim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.LearnMaskedDefault">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">LearnMaskedDefault</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">feature_dim</span></em>, <em class="sig-param"><span class="n">init_method</span><span class="o">=</span><span class="default_value">'gaussian'</span></em>, <em class="sig-param"><span class="n">freeze</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LearnMaskedDefault"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LearnMaskedDefault" title="Permalink to this definition">¶</a></dt>
<dd><p>Learns default values to fill invalid entries within input tensors. The
invalid entries are represented by a mask which is passed into forward alongside
the input tensor. Note the default value is only used if all entries in the batch row are
invalid rather than just a portion of invalid entries within each batch row.</p>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.LearnMaskedDefault.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">feature_dim</span></em>, <em class="sig-param"><span class="n">init_method</span><span class="o">=</span><span class="default_value">'gaussian'</span></em>, <em class="sig-param"><span class="n">freeze</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LearnMaskedDefault.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LearnMaskedDefault.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_dim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the size of the default value parameter, this must match the
input tensor size.</p></li>
<li><p><strong>init_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – the initial default value parameter. Options:
‘guassian’
‘zeros’</p></li>
<li><p><strong>freeze</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If True, the learned default parameter weights are frozen.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.LearnMaskedDefault.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">mask</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LearnMaskedDefault.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LearnMaskedDefault.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – tensor of shape (batch_size, feature_dim).</p></li>
<li><p><strong>mask</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – bool tensor of shape (batch_size, seq_len) If all elements
in the batch dimension are False the learned default parameter is used for
that batch element.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with shape (batch_size, feature_dim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.LSTM">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">LSTM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim_in</span></em>, <em class="sig-param"><span class="n">hidden_dim</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">bidirectional</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LSTM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for torch.nn.LSTM that handles masked inputs.</p>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.LSTM.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim_in</span></em>, <em class="sig-param"><span class="n">hidden_dim</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">bidirectional</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LSTM.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LSTM.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input feature dimension</p></li>
<li><p><strong>hidden_dim</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – hidden dimesion of lstm layer</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – dropout rate - 0.0 if no dropout</p></li>
<li><p><strong>bidirectional</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – bidirectional or forward only</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.LSTM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#LSTM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.LSTM.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – tensor with shape (batch_size, seq_len, feature_dim)</p></li>
<li><p><strong>mask</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – bool tensor with shape (batch_size, seq_len).
Sequence elements that are False are invalid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tensor with shape (batch_size, output_dim) - outoput_dim is determined by</dt><dd><p>hidden_dim and whether bidirectional or not</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.TransposeTransformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">TransposeTransformerEncoder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim_in</span></em>, <em class="sig-param"><span class="n">num_heads</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">num_layers</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeTransformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeTransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for torch.nn.TransformerEncoder that handles masked inputs.</p>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.TransposeTransformerEncoder.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dim_in</span></em>, <em class="sig-param"><span class="n">num_heads</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">num_layers</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeTransformerEncoder.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeTransformerEncoder.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input feature dimension</p></li>
<li><p><strong>num_heads</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of heads in the nn.MultiHeadAttention layers</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the number of sub-encoder-layers in the encoder</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.TransposeTransformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#TransposeTransformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.TransposeTransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – tensor with shape (batch_size, seq_len, feature_dim)</p></li>
<li><p><strong>mask</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))"><em>torch.Tensor</em></a>) – bool tensor with shape (batch_size, seq_len).
Sequence elements that are False are invalid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with shape (batch_size, feature_dim)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+git12d5971 ))">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.MaskedSequential">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">MaskedSequential</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedSequential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedSequential" title="Permalink to this definition">¶</a></dt>
<dd><p>A sequential container that overrides forward to take a mask as well as the usual
input tensor. This mask is only applied to modules in _MASK_MODULES (which take
the mask argument).</p>
</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.masked_multistream.MaskedMultiPathWay">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.masked_multistream.</code><code class="sig-name descname">MaskedMultiPathWay</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">multipathway_blocks</span></em>, <em class="sig-param"><span class="n">multipathway_fusion</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedMultiPathWay"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedMultiPathWay" title="Permalink to this definition">¶</a></dt>
<dd><p>Masked multi-pathway is composed of a list of stream nn.Modules followed by a
fusion nn.Module that reduces these streams. Each stream module takes a mask
and input tensor.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Pathway 1  ... Pathway N
    ↓              ↓
 Block 1        Block N
    ↓⭠ --Fusion----↓
</pre></div>
</div>
<dl class="py method">
<dt id="pytorchvideo.models.masked_multistream.MaskedMultiPathWay.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">multipathway_blocks</span></em>, <em class="sig-param"><span class="n">multipathway_fusion</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/masked_multistream.html#MaskedMultiPathWay.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.masked_multistream.MaskedMultiPathWay.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multipathway_blocks</strong> (<em>nn.module_list</em>) – list of models from all pathways.</p></li>
<li><p><strong>multipathway_fusion</strong> (<em>nn.module</em>) – fusion model.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/constants.html#None" title="(in Python v3.6)">None</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


             </article>
             
            </div>
            <!-- <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../docs/data.html" class="btn btn-neutral float-right" title="Overview" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="memory_bank.html" class="btn btn-neutral" title="pytorchvideo.models.memory_bank" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">pytorchvideo.models.masked_multistream</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>