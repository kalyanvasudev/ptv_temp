


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.x3d &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
  
  
  
    <link rel="canonical" href="https://pytorchvideo.org/docs/_modules/pytorchvideo/models/x3d.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/models/index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>pytorchvideo.models.x3d</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pytorchvideo.models.x3d</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">fvcore.nn.squeeze_excitation</span> <span class="kn">import</span> <span class="n">SqueezeExcitation</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.convolutions</span> <span class="kn">import</span> <span class="n">Conv2plus1d</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.swish</span> <span class="kn">import</span> <span class="n">Swish</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.utils</span> <span class="kn">import</span> <span class="n">round_repeats</span><span class="p">,</span> <span class="n">round_width</span><span class="p">,</span> <span class="n">set_attributes</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.head</span> <span class="kn">import</span> <span class="n">ResNetBasicHead</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.net</span> <span class="kn">import</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.resnet</span> <span class="kn">import</span> <span class="n">BottleneckBlock</span><span class="p">,</span> <span class="n">ResBlock</span><span class="p">,</span> <span class="n">ResStage</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.stem</span> <span class="kn">import</span> <span class="n">ResNetBasicStem</span>


<div class="viewcode-block" id="create_x3d_stem"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d_stem">[docs]</a><span class="k">def</span> <span class="nf">create_x3d_stem</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Conv configs.</span>
    <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">conv_padding</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="c1"># BN configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates the stem layer for X3D. It performs spatial Conv, temporal Conv, BN, and Relu.</span>

<span class="sd">    ::</span>

<span class="sd">                                        Conv_xy</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                        Conv_t</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                     Normalization</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       Activation</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channels (int): input channel size of the convolution.</span>
<span class="sd">        out_channels (int): output channel size of the convolution.</span>
<span class="sd">        conv_kernel_size (tuple): convolutional kernel size(s).</span>
<span class="sd">        conv_stride (tuple): convolutional stride size(s).</span>
<span class="sd">        conv_padding (tuple): convolutional padding size(s).</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer, options</span>
<span class="sd">            include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer, options</span>
<span class="sd">            include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">            activation).</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): X3D stem layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">conv_xy_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
        <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv_stride</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
        <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">conv_padding</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv_padding</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">conv_t_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="n">conv_kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="n">conv_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">conv_padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">stacked_conv_module</span> <span class="o">=</span> <span class="n">Conv2plus1d</span><span class="p">(</span>
        <span class="n">conv_t</span><span class="o">=</span><span class="n">conv_xy_module</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">conv_xy</span><span class="o">=</span><span class="n">conv_t_module</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">norm_module</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">activation_module</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">activation</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">ResNetBasicStem</span><span class="p">(</span>
        <span class="n">conv</span><span class="o">=</span><span class="n">stacked_conv_module</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm_module</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation_module</span><span class="p">,</span>
        <span class="n">pool</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="create_x3d_bottleneck_block"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d_bottleneck_block">[docs]</a><span class="k">def</span> <span class="nf">create_x3d_bottleneck_block</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Convolution configs.</span>
    <span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="c1"># Norm configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">se_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0625</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">inner_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">Swish</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bottleneck block for X3D: a sequence of Conv, Normalization with optional SE block,</span>
<span class="sd">    and Activations repeated in the following order:</span>

<span class="sd">    ::</span>

<span class="sd">                                    Conv3d (conv_a)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Normalization (norm_a)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                   Activation (act_a)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                    Conv3d (conv_b)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Normalization (norm_b)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Squeeze-and-Excitation</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                   Activation (act_b)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                    Conv3d (conv_c)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Normalization (norm_c)</span>

<span class="sd">    Args:</span>
<span class="sd">        dim_in (int): input channel size to the bottleneck block.</span>
<span class="sd">        dim_inner (int): intermediate channel size of the bottleneck.</span>
<span class="sd">        dim_out (int): output channel size of the bottleneck.</span>
<span class="sd">        conv_kernel_size (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        conv_stride (tuple): convolutional stride size(s) for conv_b.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">            include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>
<span class="sd">        se_ratio (float): if &gt; 0, apply SE to the 3x3x3 conv, with the SE</span>
<span class="sd">            channel dimensionality being se_ratio times the 3x3x3 conv dim.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer, examples</span>
<span class="sd">            include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">            activation).</span>
<span class="sd">        inner_act (callable): whether use Swish activation for act_b or not.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): X3D bottleneck block.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1x1x1 Conv</span>
    <span class="n">conv_a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">norm_a</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">act_a</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">activation</span><span class="p">()</span>

    <span class="c1"># 3x3x3 Conv</span>
    <span class="n">conv_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">conv_kernel_size</span><span class="p">],</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">se</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">SqueezeExcitation</span><span class="p">(</span>
            <span class="n">num_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
            <span class="n">num_channels_reduced</span><span class="o">=</span><span class="n">round_width</span><span class="p">(</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">se_ratio</span><span class="p">),</span>
            <span class="n">is_3d</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">se_ratio</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">norm_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">se</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">act_b</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">inner_act</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">inner_act</span><span class="p">()</span>

    <span class="c1"># 1x1x1 Conv</span>
    <span class="n">conv_c</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">norm_c</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">BottleneckBlock</span><span class="p">(</span>
        <span class="n">conv_a</span><span class="o">=</span><span class="n">conv_a</span><span class="p">,</span>
        <span class="n">norm_a</span><span class="o">=</span><span class="n">norm_a</span><span class="p">,</span>
        <span class="n">act_a</span><span class="o">=</span><span class="n">act_a</span><span class="p">,</span>
        <span class="n">conv_b</span><span class="o">=</span><span class="n">conv_b</span><span class="p">,</span>
        <span class="n">norm_b</span><span class="o">=</span><span class="n">norm_b</span><span class="p">,</span>
        <span class="n">act_b</span><span class="o">=</span><span class="n">act_b</span><span class="p">,</span>
        <span class="n">conv_c</span><span class="o">=</span><span class="n">conv_c</span><span class="p">,</span>
        <span class="n">norm_c</span><span class="o">=</span><span class="n">norm_c</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="create_x3d_res_block"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d_res_block">[docs]</a><span class="k">def</span> <span class="nf">create_x3d_res_block</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Bottleneck Block configs.</span>
    <span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">bottleneck</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">create_x3d_bottleneck_block</span><span class="p">,</span>
    <span class="n">use_shortcut</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># Conv configs.</span>
    <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="c1"># Norm configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">se_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0625</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">inner_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">Swish</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Residual block for X3D. Performs a summation between an identity shortcut in branch1 and a</span>
<span class="sd">    main block in branch2. When the input and output dimensions are different, a</span>
<span class="sd">    convolution followed by a normalization will be performed.</span>

<span class="sd">    ::</span>

<span class="sd">                                         Input</span>
<span class="sd">                                           |-------+</span>
<span class="sd">                                           ↓       |</span>
<span class="sd">                                         Block     |</span>
<span class="sd">                                           ↓       |</span>
<span class="sd">                                       Summation ←-+</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       Activation</span>

<span class="sd">    Args:</span>
<span class="sd">        dim_in (int): input channel size to the bottleneck block.</span>
<span class="sd">        dim_inner (int): intermediate channel size of the bottleneck.</span>
<span class="sd">        dim_out (int): output channel size of the bottleneck.</span>
<span class="sd">        bottleneck (callable): a callable for create_x3d_bottleneck_block.</span>

<span class="sd">        conv_kernel_size (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        conv_stride (tuple): convolutional stride size(s) for conv_b.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">            include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>
<span class="sd">        se_ratio (float): if &gt; 0, apply SE to the 3x3x3 conv, with the SE</span>
<span class="sd">            channel dimensionality being se_ratio times the 3x3x3 conv dim.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer, examples</span>
<span class="sd">            include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">            activation).</span>
<span class="sd">        inner_act (callable): whether use Swish activation for act_b or not.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): X3D block layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">norm_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dim_in</span> <span class="o">!=</span> <span class="n">dim_out</span><span class="p">:</span>
        <span class="n">norm_model</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_out</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ResBlock</span><span class="p">(</span>
        <span class="n">branch1_conv</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
            <span class="n">dim_in</span><span class="p">,</span>
            <span class="n">dim_out</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dim_in</span> <span class="o">!=</span> <span class="n">dim_out</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">conv_stride</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="n">use_shortcut</span>
        <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">branch1_norm</span><span class="o">=</span><span class="n">norm_model</span> <span class="k">if</span> <span class="n">dim_in</span> <span class="o">!=</span> <span class="n">dim_out</span> <span class="ow">and</span> <span class="n">use_shortcut</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">branch2</span><span class="o">=</span><span class="n">bottleneck</span><span class="p">(</span>
            <span class="n">dim_in</span><span class="o">=</span><span class="n">dim_in</span><span class="p">,</span>
            <span class="n">dim_inner</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
            <span class="n">dim_out</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span>
            <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">,</span>
            <span class="n">conv_stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
            <span class="n">norm_eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span>
            <span class="n">norm_momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">,</span>
            <span class="n">se_ratio</span><span class="o">=</span><span class="n">se_ratio</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">inner_act</span><span class="o">=</span><span class="n">inner_act</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">activation</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">activation</span><span class="p">(),</span>
        <span class="n">branch_fusion</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="create_x3d_res_stage"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d_res_stage">[docs]</a><span class="k">def</span> <span class="nf">create_x3d_res_stage</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Stage configs.</span>
    <span class="n">depth</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="c1"># Bottleneck Block configs.</span>
    <span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">bottleneck</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">create_x3d_bottleneck_block</span><span class="p">,</span>
    <span class="c1"># Conv configs.</span>
    <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="c1"># Norm configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">se_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0625</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">inner_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">Swish</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create Residual Stage, which composes sequential blocks that make up X3D.</span>

<span class="sd">    ::</span>

<span class="sd">                                        Input</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       ResBlock</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                           .</span>
<span class="sd">                                           .</span>
<span class="sd">                                           .</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       ResBlock</span>

<span class="sd">    Args:</span>

<span class="sd">        depth (init): number of blocks to create.</span>

<span class="sd">        dim_in (int): input channel size to the bottleneck block.</span>
<span class="sd">        dim_inner (int): intermediate channel size of the bottleneck.</span>
<span class="sd">        dim_out (int): output channel size of the bottleneck.</span>
<span class="sd">        bottleneck (callable): a callable for create_x3d_bottleneck_block.</span>

<span class="sd">        conv_kernel_size (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        conv_stride (tuple): convolutional stride size(s) for conv_b.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">            include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>
<span class="sd">        se_ratio (float): if &gt; 0, apply SE to the 3x3x3 conv, with the SE</span>
<span class="sd">            channel dimensionality being se_ratio times the 3x3x3 conv dim.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer, examples</span>
<span class="sd">            include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">            activation).</span>
<span class="sd">        inner_act (callable): whether use Swish activation for act_b or not.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): X3D stage layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res_blocks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">create_x3d_res_block</span><span class="p">(</span>
            <span class="n">dim_in</span><span class="o">=</span><span class="n">dim_in</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">dim_out</span><span class="p">,</span>
            <span class="n">dim_inner</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
            <span class="n">dim_out</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span>
            <span class="n">bottleneck</span><span class="o">=</span><span class="n">bottleneck</span><span class="p">,</span>
            <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">,</span>
            <span class="n">conv_stride</span><span class="o">=</span><span class="n">conv_stride</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
            <span class="n">norm_eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span>
            <span class="n">norm_momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">,</span>
            <span class="n">se_ratio</span><span class="o">=</span><span class="p">(</span><span class="n">se_ratio</span> <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">),</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">inner_act</span><span class="o">=</span><span class="n">inner_act</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">res_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ResStage</span><span class="p">(</span><span class="n">res_blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">res_blocks</span><span class="p">))</span></div>


<div class="viewcode-block" id="create_x3d_head"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d_head">[docs]</a><span class="k">def</span> <span class="nf">create_x3d_head</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Projection configs.</span>
    <span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="c1"># Pooling configs.</span>
    <span class="n">pool_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">pool_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="c1"># BN configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">bn_lin5_on</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="c1"># Dropout configs.</span>
    <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">,</span>
    <span class="c1"># Output configs.</span>
    <span class="n">output_with_global_average</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates X3D head. This layer performs an projected pooling operation followed</span>
<span class="sd">    by an dropout, a fully-connected projection, an activation layer and a global</span>
<span class="sd">    spatiotemporal averaging.</span>

<span class="sd">    ::</span>

<span class="sd">                                     ProjectedPool</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                        Dropout</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       Projection</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       Activation</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                       Averaging</span>

<span class="sd">    Args:</span>
<span class="sd">        dim_in (int): input channel size of the X3D head.</span>
<span class="sd">        dim_inner (int): intermediate channel size of the X3D head.</span>
<span class="sd">        dim_out (int): output channel size of the X3D head.</span>
<span class="sd">        num_classes (int): the number of classes for the video dataset.</span>

<span class="sd">        pool_act (callable): a callable that constructs resnet pool activation</span>
<span class="sd">            layer such as nn.ReLU.</span>
<span class="sd">        pool_kernel_size (tuple): pooling kernel size(s) when not using adaptive</span>
<span class="sd">            pooling.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">            include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>
<span class="sd">        bn_lin5_on (bool): if True, perform normalization on the features</span>
<span class="sd">            before the classifier.</span>

<span class="sd">        dropout_rate (float): dropout rate.</span>

<span class="sd">        activation (callable): a callable that constructs resnet head activation</span>
<span class="sd">            layer, examples include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not</span>
<span class="sd">            applying activation).</span>

<span class="sd">        output_with_global_average (bool): if True, perform global averaging on temporal</span>
<span class="sd">            and spatial dimensions and reshape output to batch_size x out_features.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): X3D head layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pre_conv_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="n">pre_norm_module</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>
    <span class="n">pre_act_module</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">pool_act</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pool_act</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">pool_kernel_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pool_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pool_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="n">pool_kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">post_conv_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">bn_lin5_on</span><span class="p">:</span>
        <span class="n">post_norm_module</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span>
            <span class="n">num_features</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">post_norm_module</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">post_act_module</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">pool_act</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pool_act</span><span class="p">()</span>

    <span class="n">projected_pool_module</span> <span class="o">=</span> <span class="n">ProjectedPool</span><span class="p">(</span>
        <span class="n">pre_conv</span><span class="o">=</span><span class="n">pre_conv_module</span><span class="p">,</span>
        <span class="n">pre_norm</span><span class="o">=</span><span class="n">pre_norm_module</span><span class="p">,</span>
        <span class="n">pre_act</span><span class="o">=</span><span class="n">pre_act_module</span><span class="p">,</span>
        <span class="n">pool</span><span class="o">=</span><span class="n">pool_module</span><span class="p">,</span>
        <span class="n">post_conv</span><span class="o">=</span><span class="n">post_conv_module</span><span class="p">,</span>
        <span class="n">post_norm</span><span class="o">=</span><span class="n">post_norm_module</span><span class="p">,</span>
        <span class="n">post_act</span><span class="o">=</span><span class="n">post_act_module</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">activation_module</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">:</span>
        <span class="n">activation_module</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">:</span>
        <span class="n">activation_module</span> <span class="o">=</span> <span class="n">activation</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> is not supported as an activation&quot;</span> <span class="s2">&quot;function.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">output_with_global_average</span><span class="p">:</span>
        <span class="n">output_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_pool</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">ResNetBasicHead</span><span class="p">(</span>
        <span class="n">proj</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation_module</span><span class="p">,</span>
        <span class="n">pool</span><span class="o">=</span><span class="n">projected_pool_module</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout_rate</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_pool</span><span class="o">=</span><span class="n">output_pool</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="create_x3d"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.create_x3d">[docs]</a><span class="k">def</span> <span class="nf">create_x3d</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Input clip configs.</span>
    <span class="n">input_channel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">input_clip_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">13</span><span class="p">,</span>
    <span class="n">input_crop_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">160</span><span class="p">,</span>
    <span class="c1"># Model configs.</span>
    <span class="n">model_num_class</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">width_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
    <span class="n">depth_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.2</span><span class="p">,</span>
    <span class="c1"># Normalization configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="c1"># Stem configs.</span>
    <span class="n">stem_dim_in</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
    <span class="n">stem_conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">stem_conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="c1"># Stage configs.</span>
    <span class="n">stage_conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">stage_spatial_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">stage_temporal_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">bottleneck</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">create_x3d_bottleneck_block</span><span class="p">,</span>
    <span class="n">bottleneck_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.25</span><span class="p">,</span>
    <span class="n">se_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0625</span><span class="p">,</span>
    <span class="n">inner_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">Swish</span><span class="p">,</span>
    <span class="c1"># Head configs.</span>
    <span class="n">head_dim_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">head_pool_act</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="n">head_bn_lin5_on</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">head_activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">,</span>
    <span class="n">head_output_with_global_average</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    X3D model builder. It builds a X3D network backbone, which is a ResNet.</span>

<span class="sd">    Christoph Feichtenhofer.</span>
<span class="sd">    &quot;X3D: Expanding Architectures for Efficient Video Recognition.&quot;</span>
<span class="sd">    https://arxiv.org/abs/2004.04730</span>

<span class="sd">    ::</span>

<span class="sd">                                         Input</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                         Stem</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                         Stage 1</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                           .</span>
<span class="sd">                                           .</span>
<span class="sd">                                           .</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                         Stage N</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                         Head</span>

<span class="sd">    Args:</span>
<span class="sd">        input_channel (int): number of channels for the input video clip.</span>
<span class="sd">        input_clip_length (int): length of the input video clip. Value for</span>
<span class="sd">            different models: X3D-XS: 4; X3D-S: 13; X3D-M: 16; X3D-L: 16.</span>
<span class="sd">        input_crop_size (int): spatial resolution of the input video clip.</span>
<span class="sd">            Value for different models: X3D-XS: 160; X3D-S: 160; X3D-M: 224;</span>
<span class="sd">            X3D-L: 312.</span>

<span class="sd">        model_num_class (int): the number of classes for the video dataset.</span>
<span class="sd">        dropout_rate (float): dropout rate.</span>
<span class="sd">        width_factor (float): width expansion factor.</span>
<span class="sd">        depth_factor (float): depth expansion factor. Value for different</span>
<span class="sd">            models: X3D-XS: 2.2; X3D-S: 2.2; X3D-M: 2.2; X3D-L: 5.0.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer.</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer.</span>

<span class="sd">        stem_dim_in (int): input channel size for stem before expansion.</span>
<span class="sd">        stem_conv_kernel_size (tuple): convolutional kernel size(s) of stem.</span>
<span class="sd">        stem_conv_stride (tuple): convolutional stride size(s) of stem.</span>

<span class="sd">        stage_conv_kernel_size (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        stage_spatial_stride (tuple): the spatial stride for each stage.</span>
<span class="sd">        stage_temporal_stride (tuple): the temporal stride for each stage.</span>
<span class="sd">        bottleneck_factor (float): bottleneck expansion factor for the 3x3x3 conv.</span>
<span class="sd">        se_ratio (float): if &gt; 0, apply SE to the 3x3x3 conv, with the SE</span>
<span class="sd">            channel dimensionality being se_ratio times the 3x3x3 conv dim.</span>
<span class="sd">        inner_act (callable): whether use Swish activation for act_b or not.</span>

<span class="sd">        head_dim_out (int): output channel size of the X3D head.</span>
<span class="sd">        head_pool_act (callable): a callable that constructs resnet pool activation</span>
<span class="sd">            layer such as nn.ReLU.</span>
<span class="sd">        head_bn_lin5_on (bool): if True, perform normalization on the features</span>
<span class="sd">            before the classifier.</span>
<span class="sd">        head_activation (callable): a callable that constructs activation layer.</span>
<span class="sd">        head_output_with_global_average (bool): if True, perform global averaging on</span>
<span class="sd">            the head output.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): the X3D network.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Create stem for X3D.</span>
    <span class="n">stem_dim_out</span> <span class="o">=</span> <span class="n">round_width</span><span class="p">(</span><span class="n">stem_dim_in</span><span class="p">,</span> <span class="n">width_factor</span><span class="p">)</span>
    <span class="n">stem</span> <span class="o">=</span> <span class="n">create_x3d_stem</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">input_channel</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">stem_dim_out</span><span class="p">,</span>
        <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">stem_conv_kernel_size</span><span class="p">,</span>
        <span class="n">conv_stride</span><span class="o">=</span><span class="n">stem_conv_stride</span><span class="p">,</span>
        <span class="n">conv_padding</span><span class="o">=</span><span class="p">[</span><span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stem_conv_kernel_size</span><span class="p">],</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
        <span class="n">norm_eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span>
        <span class="n">norm_momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stem</span><span class="p">)</span>

    <span class="c1"># Compute the depth and dimension for each stage</span>
    <span class="n">stage_depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">exp_stage</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">stage_dim1</span> <span class="o">=</span> <span class="n">stem_dim_in</span>
    <span class="n">stage_dim2</span> <span class="o">=</span> <span class="n">round_width</span><span class="p">(</span><span class="n">stage_dim1</span><span class="p">,</span> <span class="n">exp_stage</span><span class="p">,</span> <span class="n">divisor</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">stage_dim3</span> <span class="o">=</span> <span class="n">round_width</span><span class="p">(</span><span class="n">stage_dim2</span><span class="p">,</span> <span class="n">exp_stage</span><span class="p">,</span> <span class="n">divisor</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">stage_dim4</span> <span class="o">=</span> <span class="n">round_width</span><span class="p">(</span><span class="n">stage_dim3</span><span class="p">,</span> <span class="n">exp_stage</span><span class="p">,</span> <span class="n">divisor</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">stage_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">stage_dim1</span><span class="p">,</span> <span class="n">stage_dim2</span><span class="p">,</span> <span class="n">stage_dim3</span><span class="p">,</span> <span class="n">stage_dim4</span><span class="p">]</span>

    <span class="n">dim_in</span> <span class="o">=</span> <span class="n">stem_dim_out</span>
    <span class="c1"># Create each stage for X3D.</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)):</span>
        <span class="n">dim_out</span> <span class="o">=</span> <span class="n">round_width</span><span class="p">(</span><span class="n">stage_dims</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">width_factor</span><span class="p">)</span>
        <span class="n">dim_inner</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bottleneck_factor</span> <span class="o">*</span> <span class="n">dim_out</span><span class="p">)</span>
        <span class="n">depth</span> <span class="o">=</span> <span class="n">round_repeats</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">depth_factor</span><span class="p">)</span>

        <span class="n">stage_conv_stride</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">stage_temporal_stride</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
            <span class="n">stage_spatial_stride</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
            <span class="n">stage_spatial_stride</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">stage</span> <span class="o">=</span> <span class="n">create_x3d_res_stage</span><span class="p">(</span>
            <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
            <span class="n">dim_in</span><span class="o">=</span><span class="n">dim_in</span><span class="p">,</span>
            <span class="n">dim_inner</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
            <span class="n">dim_out</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span>
            <span class="n">bottleneck</span><span class="o">=</span><span class="n">bottleneck</span><span class="p">,</span>
            <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">stage_conv_kernel_size</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
            <span class="n">conv_stride</span><span class="o">=</span><span class="n">stage_conv_stride</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
            <span class="n">norm_eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span>
            <span class="n">norm_momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">,</span>
            <span class="n">se_ratio</span><span class="o">=</span><span class="n">se_ratio</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">inner_act</span><span class="o">=</span><span class="n">inner_act</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
        <span class="n">dim_in</span> <span class="o">=</span> <span class="n">dim_out</span>

    <span class="c1"># Create head for X3D.</span>
    <span class="n">total_spatial_stride</span> <span class="o">=</span> <span class="n">stem_conv_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">stage_spatial_stride</span><span class="p">)</span>
    <span class="n">total_temporal_stride</span> <span class="o">=</span> <span class="n">stem_conv_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">stage_temporal_stride</span><span class="p">)</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">input_clip_length</span> <span class="o">&gt;=</span> <span class="n">total_temporal_stride</span>
    <span class="p">),</span> <span class="s2">&quot;Clip length doesn&#39;t match temporal stride!&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">input_crop_size</span> <span class="o">&gt;=</span> <span class="n">total_spatial_stride</span>
    <span class="p">),</span> <span class="s2">&quot;Crop size doesn&#39;t match spatial stride!&quot;</span>

    <span class="n">head_pool_kernel_size</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">input_clip_length</span> <span class="o">//</span> <span class="n">total_temporal_stride</span><span class="p">,</span>
        <span class="n">input_crop_size</span> <span class="o">//</span> <span class="n">total_spatial_stride</span><span class="p">,</span>
        <span class="n">input_crop_size</span> <span class="o">//</span> <span class="n">total_spatial_stride</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">head</span> <span class="o">=</span> <span class="n">create_x3d_head</span><span class="p">(</span>
        <span class="n">dim_in</span><span class="o">=</span><span class="n">dim_out</span><span class="p">,</span>
        <span class="n">dim_inner</span><span class="o">=</span><span class="n">dim_inner</span><span class="p">,</span>
        <span class="n">dim_out</span><span class="o">=</span><span class="n">head_dim_out</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="n">model_num_class</span><span class="p">,</span>
        <span class="n">pool_act</span><span class="o">=</span><span class="n">head_pool_act</span><span class="p">,</span>
        <span class="n">pool_kernel_size</span><span class="o">=</span><span class="n">head_pool_kernel_size</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
        <span class="n">norm_eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span>
        <span class="n">norm_momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">,</span>
        <span class="n">bn_lin5_on</span><span class="o">=</span><span class="n">head_bn_lin5_on</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">head_activation</span><span class="p">,</span>
        <span class="n">output_with_global_average</span><span class="o">=</span><span class="n">head_output_with_global_average</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Net</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">blocks</span><span class="p">))</span></div>


<div class="viewcode-block" id="ProjectedPool"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.ProjectedPool">[docs]</a><span class="k">class</span> <span class="nc">ProjectedPool</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A pooling module augmented with Conv, Normalization and Activation both</span>
<span class="sd">    before and after pooling for the head layer of X3D.</span>

<span class="sd">    ::</span>

<span class="sd">                                    Conv3d (pre_conv)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Normalization (pre_norm)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                   Activation (pre_act)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                        Pool3d</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                    Conv3d (post_conv)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                 Normalization (post_norm)</span>
<span class="sd">                                           ↓</span>
<span class="sd">                                   Activation (post_act)</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ProjectedPool.__init__"><a class="viewcode-back" href="../../../api/models/x3d.html#pytorchvideo.models.x3d.ProjectedPool.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">pre_conv</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pre_norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pre_act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pool</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">post_conv</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">post_norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">post_act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            pre_conv (torch.nn.modules): convolutional module.</span>
<span class="sd">            pre_norm (torch.nn.modules): normalization module.</span>
<span class="sd">            pre_act (torch.nn.modules): activation module.</span>
<span class="sd">            pool (torch.nn.modules): pooling module.</span>
<span class="sd">            post_conv (torch.nn.modules): convolutional module.</span>
<span class="sd">            post_norm (torch.nn.modules): normalization module.</span>
<span class="sd">            post_act (torch.nn.modules): activation module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_conv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_conv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span></div>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_act</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_act</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>
</pre></div>

             </article>
             
            </div>
            <!-- <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>