


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.slowfast &mdash; PyTorchVideo  documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://kalyanvasudev.github.io/ptv_temp/api/_modules/pytorchvideo/models/slowfast.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://kalyanvasudev.github.io/ptv_temp/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/">Home</a>
          </li>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">PyTorchVideo/Model</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../transforms.html">Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo.html">PyTorchVideo Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data_preparation.html">Data Preparation</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">API Documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>pytorchvideo.models.slowfast</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pytorchvideo.models.slowfast</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.utils</span> <span class="kn">import</span> <span class="n">set_attributes</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.head</span> <span class="kn">import</span> <span class="n">create_res_basic_head</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.net</span> <span class="kn">import</span> <span class="n">MultiPathWayWithFuse</span><span class="p">,</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.resnet</span> <span class="kn">import</span> <span class="n">create_bottleneck_block</span><span class="p">,</span> <span class="n">create_res_stage</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.stem</span> <span class="kn">import</span> <span class="n">create_res_basic_stem</span>


<div class="viewcode-block" id="create_slowfast"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.create_slowfast">[docs]</a><span class="k">def</span> <span class="nf">create_slowfast</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># SlowFast configs.</span>
    <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,),</span>
    <span class="n">slowfast_conv_channel_fusion_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">slowfast_fusion_conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">7</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
    <span class="p">),</span>  <span class="c1"># deprecated, use fusion_builder</span>
    <span class="n">slowfast_fusion_conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
    <span class="p">),</span>  <span class="c1"># deprecated, use fusion_builder</span>
    <span class="n">fusion_builder</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
        <span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Args: fusion_dim_in, stage_idx</span>
    <span class="c1"># Input clip configs.</span>
    <span class="n">input_channels</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="c1"># Model configs.</span>
    <span class="n">model_depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">model_num_class</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="c1"># Normalization configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="c1"># Stem configs.</span>
    <span class="n">stem_function</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">create_res_basic_stem</span><span class="p">,</span>
        <span class="n">create_res_basic_stem</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">stem_dim_outs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="n">stem_conv_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
    <span class="n">stem_conv_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">stem_pool</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">),</span>
    <span class="n">stem_pool_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">stem_pool_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="c1"># Stage configs.</span>
    <span class="n">stage_conv_a_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_conv_b_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_conv_b_num_groups</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">stage_conv_b_dilations</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_spatial_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">stage_temporal_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">bottleneck</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="p">(</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="c1"># Head configs.</span>
    <span class="n">head_pool</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">,</span>
    <span class="n">head_pool_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
    <span class="n">head_output_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">head_activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">head_output_with_global_average</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build SlowFast model for video recognition, SlowFast model involves a Slow pathway,</span>
<span class="sd">    operating at low frame rate, to capture spatial semantics, and a Fast pathway,</span>
<span class="sd">    operating at high frame rate, to capture motion at fine temporal resolution. The</span>
<span class="sd">    Fast pathway can be made very lightweight by reducing its channel capacity, yet can</span>
<span class="sd">    learn useful temporal information for video recognition. Details can be found from</span>
<span class="sd">    the paper:</span>

<span class="sd">    Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.</span>
<span class="sd">    &quot;SlowFast networks for video recognition.&quot;</span>
<span class="sd">    https://arxiv.org/pdf/1812.03982.pdf</span>

<span class="sd">    ::</span>

<span class="sd">                             Slow Input  Fast Input</span>
<span class="sd">                                  ↓           ↓</span>
<span class="sd">                                 Stem       Stem</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                               Stage 1     Stage 1</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                                  .           .</span>
<span class="sd">                                  ↓           ↓</span>
<span class="sd">                               Stage N     Stage N</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                                         ↓</span>
<span class="sd">                                       Head</span>

<span class="sd">    Args:</span>
<span class="sd">        slowfast_channel_reduction_ratio (int): Corresponds to the inverse of the channel</span>
<span class="sd">            reduction ratio, $\beta$ between the Slow and Fast pathways.</span>
<span class="sd">        slowfast_conv_channel_fusion_ratio (int): Ratio of channel dimensions</span>
<span class="sd">            between the Slow and Fast pathways.</span>
<span class="sd">        DEPRECATED slowfast_fusion_conv_kernel_size (tuple): the convolutional kernel</span>
<span class="sd">            size used for fusion.</span>
<span class="sd">        DEPRECATED slowfast_fusion_conv_stride (tuple): the convolutional stride size</span>
<span class="sd">            used for fusion.</span>
<span class="sd">        fusion_builder (Callable[[int, int], nn.Module]): Builder function for generating</span>
<span class="sd">            the fusion modules based on stage dimension and index</span>

<span class="sd">        input_channels (tuple): number of channels for the input video clip.</span>

<span class="sd">        model_depth (int): the depth of the resnet.</span>
<span class="sd">        model_num_class (int): the number of classes for the video dataset.</span>
<span class="sd">        dropout_rate (float): dropout rate.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer.</span>

<span class="sd">        stem_function (Tuple[Callable]): a callable that constructs stem layer.</span>
<span class="sd">            Examples include create_res_basic_stem. Indexed by pathway</span>
<span class="sd">        stem_dim_outs (tuple): output channel size to stem.</span>
<span class="sd">        stem_conv_kernel_sizes (tuple): convolutional kernel size(s) of stem.</span>
<span class="sd">        stem_conv_strides (tuple): convolutional stride size(s) of stem.</span>
<span class="sd">        stem_pool (Tuple[Callable]): a callable that constructs resnet head pooling layer.</span>
<span class="sd">            Indexed by pathway</span>
<span class="sd">        stem_pool_kernel_sizes (tuple): pooling kernel size(s).</span>
<span class="sd">        stem_pool_strides (tuple): pooling stride size(s).</span>

<span class="sd">        stage_conv_a_kernel_sizes (tuple): convolutional kernel size(s) for conv_a.</span>
<span class="sd">        stage_conv_b_kernel_sizes (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        stage_conv_b_num_groups (tuple): number of groups for groupwise convolution</span>
<span class="sd">            for conv_b. 1 for ResNet, and larger than 1 for ResNeXt.</span>
<span class="sd">        stage_conv_b_dilations (tuple): dilation for 3D convolution for conv_b.</span>
<span class="sd">        stage_spatial_strides (tuple): the spatial stride for each stage.</span>
<span class="sd">        stage_temporal_strides (tuple): the temporal stride for each stage.</span>
<span class="sd">        bottleneck (Tuple[Tuple[Callable]]): a callable that constructs bottleneck</span>
<span class="sd">            block layer. Examples include: create_bottleneck_block.</span>
<span class="sd">            Indexed by pathway and stage index</span>

<span class="sd">        head_pool (callable): a callable that constructs resnet head pooling layer.</span>
<span class="sd">        head_output_sizes (tuple): the size of output tensor for head.</span>
<span class="sd">        head_activation (callable): a callable that constructs activation layer.</span>
<span class="sd">        head_output_with_global_average (bool): if True, perform global averaging on</span>
<span class="sd">            the head output.</span>
<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): SlowFast model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Number of blocks for different stages given the model depth.</span>
    <span class="n">_num_pathway</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_channels</span><span class="p">)</span>
    <span class="n">_MODEL_STAGE_DEPTH</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">18</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="mi">50</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="mi">101</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="mi">152</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">model_depth</span> <span class="ow">in</span> <span class="n">_MODEL_STAGE_DEPTH</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_depth</span><span class="si">}</span><span class="s2"> is not in </span><span class="si">{</span><span class="n">_MODEL_STAGE_DEPTH</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">stage_depths</span> <span class="o">=</span> <span class="n">_MODEL_STAGE_DEPTH</span><span class="p">[</span><span class="n">model_depth</span><span class="p">]</span>

    <span class="c1"># Fix up inputs</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">slowfast_channel_reduction_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stem_pool</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="n">stem_pool</span> <span class="o">=</span> <span class="p">(</span><span class="n">stem_pool</span><span class="p">,)</span> <span class="o">*</span> <span class="n">_num_pathway</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bottleneck</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="n">bottleneck</span> <span class="o">=</span> <span class="p">(</span><span class="n">bottleneck</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)</span>
        <span class="n">bottleneck</span> <span class="o">=</span> <span class="p">(</span><span class="n">bottleneck</span><span class="p">,)</span> <span class="o">*</span> <span class="n">_num_pathway</span>
    <span class="k">if</span> <span class="n">fusion_builder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fusion_builder</span> <span class="o">=</span> <span class="n">FastToSlowFusionBuilder</span><span class="p">(</span>
            <span class="n">slowfast_channel_reduction_ratio</span><span class="o">=</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">conv_fusion_channel_ratio</span><span class="o">=</span><span class="n">slowfast_conv_channel_fusion_ratio</span><span class="p">,</span>
            <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">slowfast_fusion_conv_kernel_size</span><span class="p">,</span>
            <span class="n">conv_stride</span><span class="o">=</span><span class="n">slowfast_fusion_conv_stride</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">max_stage_idx</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">create_module</span>

    <span class="c1"># Build stem blocks.</span>
    <span class="n">stems</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pathway_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">):</span>
        <span class="n">stems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">stem_function</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">](</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">input_channels</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">stem_dim_outs</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">stem_conv_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_stride</span><span class="o">=</span><span class="n">stem_conv_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_padding</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stem_conv_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">]</span>
                <span class="p">],</span>
                <span class="n">pool</span><span class="o">=</span><span class="n">stem_pool</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_kernel_size</span><span class="o">=</span><span class="n">stem_pool_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_stride</span><span class="o">=</span><span class="n">stem_pool_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_padding</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stem_pool_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">]</span>
                <span class="p">],</span>
                <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">stages</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">MultiPathWayWithFuse</span><span class="p">(</span>
            <span class="n">multipathway_blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stems</span><span class="p">),</span>
            <span class="n">multipathway_fusion</span><span class="o">=</span><span class="n">fusion_builder</span><span class="p">(</span>
                <span class="n">fusion_dim_in</span><span class="o">=</span><span class="n">stem_dim_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">stage_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Build stages blocks.</span>
    <span class="n">stage_dim_in</span> <span class="o">=</span> <span class="n">stem_dim_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">stage_dim_out</span> <span class="o">=</span> <span class="n">stage_dim_in</span> <span class="o">*</span> <span class="mi">4</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)):</span>
        <span class="n">pathway_stage_dim_in</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_in</span>
            <span class="o">+</span> <span class="n">stage_dim_in</span>
            <span class="o">*</span> <span class="n">slowfast_conv_channel_fusion_ratio</span>
            <span class="o">//</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">]</span>
        <span class="n">pathway_stage_dim_inner</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">pathway_stage_dim_out</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_out</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">reduction_ratio</span> <span class="ow">in</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span>
            <span class="n">pathway_stage_dim_in</span> <span class="o">=</span> <span class="n">pathway_stage_dim_in</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_in</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>
            <span class="n">pathway_stage_dim_inner</span> <span class="o">=</span> <span class="n">pathway_stage_dim_inner</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="mi">4</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>
            <span class="n">pathway_stage_dim_out</span> <span class="o">=</span> <span class="n">pathway_stage_dim_out</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>

        <span class="n">stage</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pathway_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">):</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="n">stage_depths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="n">stage_conv_a_stride</span> <span class="o">=</span> <span class="p">(</span><span class="n">stage_temporal_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">stage_conv_b_stride</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span>
                <span class="n">stage_spatial_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                <span class="n">stage_spatial_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">create_res_stage</span><span class="p">(</span>
                    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
                    <span class="n">dim_in</span><span class="o">=</span><span class="n">pathway_stage_dim_in</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">dim_inner</span><span class="o">=</span><span class="n">pathway_stage_dim_inner</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">dim_out</span><span class="o">=</span><span class="n">pathway_stage_dim_out</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">bottleneck</span><span class="o">=</span><span class="n">bottleneck</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_a_kernel_size</span><span class="o">=</span><span class="n">stage_conv_a_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_a_stride</span><span class="o">=</span><span class="n">stage_conv_a_stride</span><span class="p">,</span>
                    <span class="n">conv_a_padding</span><span class="o">=</span><span class="p">[</span>
                        <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span>
                        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stage_conv_a_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                    <span class="p">],</span>
                    <span class="n">conv_b_kernel_size</span><span class="o">=</span><span class="n">stage_conv_b_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_b_stride</span><span class="o">=</span><span class="n">stage_conv_b_stride</span><span class="p">,</span>
                    <span class="n">conv_b_padding</span><span class="o">=</span><span class="p">[</span>
                        <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span>
                        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stage_conv_b_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                    <span class="p">],</span>
                    <span class="n">conv_b_num_groups</span><span class="o">=</span><span class="n">stage_conv_b_num_groups</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_b_dilation</span><span class="o">=</span><span class="n">stage_conv_b_dilations</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">MultiPathWayWithFuse</span><span class="p">(</span>
                <span class="n">multipathway_blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stage</span><span class="p">),</span>
                <span class="n">multipathway_fusion</span><span class="o">=</span><span class="n">fusion_builder</span><span class="p">(</span>
                    <span class="n">fusion_dim_in</span><span class="o">=</span><span class="n">stage_dim_out</span><span class="p">,</span>
                    <span class="n">stage_idx</span><span class="o">=</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">stage_dim_in</span> <span class="o">=</span> <span class="n">stage_dim_out</span>
        <span class="n">stage_dim_out</span> <span class="o">=</span> <span class="n">stage_dim_out</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">head_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">head_pool</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="p">[</span><span class="n">head_pool</span><span class="p">(</span><span class="n">head_output_size</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">head_pool</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">head_pool</span><span class="p">(</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">head_pool_kernel_sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported pool_model type </span><span class="si">{</span><span class="n">pool_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PoolConcatPathway</span><span class="p">(</span><span class="n">retain_list</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pool</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">pool_model</span><span class="p">)))</span>
    <span class="n">head_in_features</span> <span class="o">=</span> <span class="n">stage_dim_in</span>
    <span class="k">for</span> <span class="n">reduction_ratio</span> <span class="ow">in</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span>
        <span class="n">head_in_features</span> <span class="o">=</span> <span class="n">head_in_features</span> <span class="o">+</span> <span class="n">stage_dim_in</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">create_res_basic_head</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">head_in_features</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">model_num_class</span><span class="p">,</span>
            <span class="n">pool</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="n">head_output_size</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">head_activation</span><span class="p">,</span>
            <span class="n">output_with_global_average</span><span class="o">=</span><span class="n">head_output_with_global_average</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">Net</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stages</span><span class="p">))</span></div>


<span class="c1"># TODO: move to pytorchvideo/layer once we have a common.py</span>
<div class="viewcode-block" id="PoolConcatPathway"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.PoolConcatPathway">[docs]</a><span class="k">class</span> <span class="nc">PoolConcatPathway</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a list of tensors, perform optional spatio-temporal pool and concatenate the</span>
<span class="sd">        tensors along the channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="PoolConcatPathway.__init__"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.PoolConcatPathway.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">retain_list</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">pool</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            retain_list (bool): if True, return the concatenated tensor in a list.</span>
<span class="sd">            pool (nn.module_list): if not None, list of pooling models for different</span>
<span class="sd">                pathway before performing concatenation.</span>
<span class="sd">            dim (int): dimension to performance concatenation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span></div>

<div class="viewcode-block" id="PoolConcatPathway.forward"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.PoolConcatPathway.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">[</span><span class="n">ind</span><span class="p">](</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
                <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">retain_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FastToSlowFusionBuilder"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FastToSlowFusionBuilder">[docs]</a><span class="k">class</span> <span class="nc">FastToSlowFusionBuilder</span><span class="p">:</span>
<div class="viewcode-block" id="FastToSlowFusionBuilder.__init__"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FastToSlowFusionBuilder.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">conv_fusion_channel_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
        <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">max_stage_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a list of two tensors from Slow pathway and Fast pathway, fusion information</span>
<span class="sd">        from the Fast pathway to the Slow on through a convolution followed by a</span>
<span class="sd">        concatenation, then return the fused list of tensors from Slow and Fast pathway in</span>
<span class="sd">        order.</span>
<span class="sd">        Args:</span>
<span class="sd">            slowfast_channel_reduction_ratio (int): Reduction ratio from the stage dimension.</span>
<span class="sd">                Used to compute conv_dim_in = fusion_dim_in // slowfast_channel_reduction_ratio</span>
<span class="sd">            conv_fusion_channel_ratio (int): channel ratio for the convolution used to fuse</span>
<span class="sd">                from Fast pathway to Slow pathway.</span>
<span class="sd">            conv_kernel_size (int): kernel size of the convolution used to fuse from Fast</span>
<span class="sd">                pathway to Slow pathway.</span>
<span class="sd">            conv_stride (int): stride size of the convolution used to fuse from Fast pathway</span>
<span class="sd">                to Slow pathway.</span>
<span class="sd">            norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">                include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">            norm_eps (float): normalization epsilon.</span>
<span class="sd">            norm_momentum (float): normalization momentum.</span>
<span class="sd">            activation (callable): a callable that constructs activation layer, examples</span>
<span class="sd">                include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">                activation).</span>
<span class="sd">            max_stage_idx (int): Returns identity module if we exceed this</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span></div>

<div class="viewcode-block" id="FastToSlowFusionBuilder.create_module"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FastToSlowFusionBuilder.create_module">[docs]</a>    <span class="k">def</span> <span class="nf">create_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fusion_dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the module for the given stage</span>
<span class="sd">        Args:</span>
<span class="sd">            fusion_dim_in (int): input stage dimension</span>
<span class="sd">            stage_idx (int): which stage this is</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stage_idx</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_stage_idx</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        <span class="n">conv_dim_in</span> <span class="o">=</span> <span class="n">fusion_dim_in</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">slowfast_channel_reduction_ratio</span>
        <span class="n">conv_fast_to_slow</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
            <span class="n">conv_dim_in</span><span class="p">,</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">conv_dim_in</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fusion_channel_ratio</span><span class="p">),</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="n">k_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">k_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel_size</span><span class="p">],</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">norm_module</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                <span class="n">num_features</span><span class="o">=</span><span class="n">conv_dim_in</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fusion_channel_ratio</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_eps</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_momentum</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">activation_module</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">FuseFastToSlow</span><span class="p">(</span>
            <span class="n">conv_fast_to_slow</span><span class="o">=</span><span class="n">conv_fast_to_slow</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm_module</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation_module</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="FuseFastToSlow"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FuseFastToSlow">[docs]</a><span class="k">class</span> <span class="nc">FuseFastToSlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a list of two tensors from Slow pathway and Fast pathway, fusion information</span>
<span class="sd">    from the Fast pathway to the Slow on through a convolution followed by a</span>
<span class="sd">    concatenation, then return the fused list of tensors from Slow and Fast pathway in</span>
<span class="sd">    order.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FuseFastToSlow.__init__"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FuseFastToSlow.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">conv_fast_to_slow</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            conv_fast_to_slow (nn.module): convolution to perform fusion.</span>
<span class="sd">            norm (nn.module): normalization module.</span>
<span class="sd">            activation (torch.nn.modules): activation module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span></div>

<div class="viewcode-block" id="FuseFastToSlow.forward"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FuseFastToSlow.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_s</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_f</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fast_to_slow</span><span class="p">(</span><span class="n">x_f</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">fuse</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">fuse</span><span class="p">)</span>
        <span class="n">x_s_fuse</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_s</span><span class="p">,</span> <span class="n">fuse</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x_s_fuse</span><span class="p">,</span> <span class="n">x_f</span><span class="p">]</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>




  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://kalyanvasudev.github.io/ptv_temp/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/">Home</a>
          </li>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>