


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.r2plus1d &mdash; PyTorchVideo  documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://kalyanvasudev.github.io/ptv_temp/api/api/models/r2plus1d.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="pytorchvideo.models.simclr" href="simclr.html" />
    <link rel="prev" title="pytorchvideo.models.slowfast" href="slowfast.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://kalyanvasudev.github.io/ptv_temp/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/">Home</a>
          </li>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">PyTorchVideo/Model</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../transforms.html">Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">PyTorchVideo Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_preparation.html">Data Preparation</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">API Documentation</a> &gt;</li>
        
          <li><a href="index.html">Models</a> &gt;</li>
        
      <li>pytorchvideo.models.r2plus1d</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/api/models/r2plus1d.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="module-pytorchvideo.models.r2plus1d">
<span id="pytorchvideo-models-r2plus1d"></span><h1>pytorchvideo.models.r2plus1d<a class="headerlink" href="#module-pytorchvideo.models.r2plus1d" title="Permalink to this headline">Â¶</a></h1>
<dl class="py function">
<dt id="pytorchvideo.models.r2plus1d.create_2plus1d_bottleneck_block">
<code class="sig-prename descclassname">pytorchvideo.models.r2plus1d.</code><code class="sig-name descname">create_2plus1d_bottleneck_block</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">conv_a_kernel_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_padding=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_a=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_b_kernel_size=(3</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">conv_b_stride=(2</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">conv_b_padding=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;function create_conv_2plus1d&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/r2plus1d.html#create_2plus1d_bottleneck_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.r2plus1d.create_2plus1d_bottleneck_block" title="Permalink to this definition">Â¶</a></dt>
<dd><p>2plus1d bottleneck block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   Conv3d (conv_a)
          â
Normalization (norm_a)
          â
  Activation (act_a)
          â
 Conv(2+1)d (conv_b)
          â
Normalization (norm_b)
          â
  Activation (act_b)
          â
   Conv3d (conv_c)
          â
Normalization (norm_c)
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â output channel size of the bottleneck.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional padding(s) for conv_a.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) â a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) â a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) â a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) â a callable that constructs normalization layer, examples
include nn.BatchNorm3d, None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) â normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) â normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) â a callable that constructs activation layer, examples
include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing
activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> â 2plus1d bottleneck block.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.r2plus1d.create_r2plus1d">
<code class="sig-prename descclassname">pytorchvideo.models.r2plus1d.</code><code class="sig-name descname">create_r2plus1d</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">input_channel=3</em>, <em class="sig-param">model_depth=50</em>, <em class="sig-param">model_num_class=400</em>, <em class="sig-param">dropout_rate=0.0</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em>, <em class="sig-param">stem_dim_out=64</em>, <em class="sig-param">stem_conv_kernel_size=(1</em>, <em class="sig-param">7</em>, <em class="sig-param">7)</em>, <em class="sig-param">stem_conv_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage_conv_a_kernel_size=((1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1))</em>, <em class="sig-param">stage_conv_b_kernel_size=((3</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(3</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(3</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(3</em>, <em class="sig-param">3</em>, <em class="sig-param">3))</em>, <em class="sig-param">stage_conv_b_num_groups=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_conv_b_dilation=((1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1))</em>, <em class="sig-param">stage_spatial_stride=(2</em>, <em class="sig-param">2</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage_temporal_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage_bottleneck=(&lt;function create_2plus1d_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_2plus1d_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_2plus1d_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_2plus1d_bottleneck_block&gt;)</em>, <em class="sig-param">head_pool=&lt;class 'torch.nn.modules.pooling.AvgPool3d'&gt;</em>, <em class="sig-param">head_pool_kernel_size=(4</em>, <em class="sig-param">7</em>, <em class="sig-param">7)</em>, <em class="sig-param">head_output_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">head_activation=&lt;class 'torch.nn.modules.activation.Softmax'&gt;</em>, <em class="sig-param">head_output_with_global_average=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/r2plus1d.html#create_r2plus1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.r2plus1d.create_r2plus1d" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Build the R(2+1)D network from::
A closer look at spatiotemporal convolutions for action recognition.
Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, Manohar Paluri. CVPR 2018.</p>
<p>R(2+1)D follows the ResNet style architecture including three parts: Stem,
Stages and Head. The three parts are assembled in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input
  â
Stem
  â
Stage 1
  â
  .
  .
  .
  â
Stage N
  â
Head
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â number of channels for the input video clip.</p></li>
<li><p><strong>model_depth</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â the depth of the resnet.</p></li>
<li><p><strong>model_num_class</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â the number of classes for the video dataset.</p></li>
<li><p><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) â dropout rate.</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) â a callable that constructs normalization layer.</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) â normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) â normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) â a callable that constructs activation layer.</p></li>
<li><p><strong>stem_dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) â output channel size for stem.</p></li>
<li><p><strong>stem_conv_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional kernel size(s) of stem.</p></li>
<li><p><strong>stem_conv_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional stride size(s) of stem.</p></li>
<li><p><strong>stage_conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>stage_conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>stage_conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â number of groups for groupwise convolution
for conv_b. 1 for ResNet, and larger than 1 for ResNeXt.</p></li>
<li><p><strong>stage_conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>stage_spatial_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â the spatial stride for each stage.</p></li>
<li><p><strong>stage_temporal_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â the temporal stride for each stage.</p></li>
<li><p><strong>stage_bottleneck</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â a callable that constructs bottleneck block layer
for each stage. Examples include: create_bottleneck_block,
create_2plus1d_bottleneck_block.</p></li>
<li><p><strong>head_pool</strong> (<em>callable</em>) â a callable that constructs resnet head pooling layer.</p></li>
<li><p><strong>head_pool_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â the pooling kernel size.</p></li>
<li><p><strong>head_output_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) â the size of output tensor for head.</p></li>
<li><p><strong>head_activation</strong> (<em>callable</em>) â a callable that constructs activation layer.</p></li>
<li><p><strong>head_output_with_global_average</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) â if True, perform global averaging on
the head output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> â basic resnet.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="simclr.html" class="btn btn-neutral float-right" title="pytorchvideo.models.simclr" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="slowfast.html" class="btn btn-neutral" title="pytorchvideo.models.slowfast" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">pytorchvideo.models.r2plus1d</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>




  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://kalyanvasudev.github.io/ptv_temp/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/">Home</a>
          </li>
          <li>
            <a href="https://kalyanvasudev.github.io/ptv_temp/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>